{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling to Identify Women's Health Concerns on Online Forums\n",
    "#### Author: Jocelyn Lutes\n",
    "---\n",
    "## Project Background\n",
    "\n",
    "Citizen science is an emerging field of research in which members of the public volunteer to participate in scientific research [(1)](https://www.citizenscience.gov/about/#). One of the most well-known, crowd-sourced citizen science is projects is [American Gut](https://msystems.asm.org/content/3/3/e00031-18), a citizen science project designed to better understand the human microbiome. For this project, citizens interested in contributing to the project paid $99 to receive a sample collection kit and were given instructions to submit the sample [(2)](https://anesthesiology.duke.edu/?p=846744). Within approximately five years, it was estimated that American Gut received samples from over 11,000 people in 45 different countries [(2)](https://anesthesiology.duke.edu/?p=846744), illustrating the willingness of individualas to participate in research and the power of citizen science for generating large datasets that can answer important research questions.\n",
    "\n",
    "The field of developmental neurotoxicology is interested in understanding the developmental origins of the nervous system throughout the lifespan [(3)](https://www.dntshome.org). Within this field, a substantial amount of research is dedicated to understanding how events that occur during a woman's pregnancy (e.g. illness, treatment with medication, psychological distress, etc.) impact the development of the baby's brain and behavior. Traditional research within the field of maternal health and infant development has relied on maternal report of any events that occurred during pregnancy through regularly-scheduled interviews with a trained research assistant or counselor. Although these interviews provide important information for the studies, the accuracy of reporting depends on the ability of the expecting mother to recall any important events that happened during her pregnancy. \n",
    "\n",
    "In order to eliminate any gaps in reporting and to gain a more-representative picture of a woman's pregnancy, we would like to to plan a citizen science project in which women who are interested in participating can download a mobile application that would allow them to log important events during their pregnancy in real time. However, understanding that this will be a large time commitment for participating women, we would also like to provide them with specially curated resources related to women's health concerns. \n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "In order to ensure that any resources that are provided in the application are relevant to potential users, the project leads have proposed that we use an open-ended survey or multiple focus groups to identify several women's health concerns. However, surveys and focus groups can be costly in terms of both time and money, and the project is operating on a limited budget and needs to be completed as quickly as possible. Additionally, it is possible that the small number of women who would be invited to join a focus group or to receive a survey would not be representative of the larger population of women who could opt to particpate in the research. Therefore, the data science team was tasked to uncover an alternate way to identify women's health concerns.\n",
    "\n",
    "In this project, **I will use natural language processing and unsupervised techniques, such as clustering and topic modeling, to identify women's health concerns from posts in online forums.** Specific concerns will be identified for general women's health, fertility and pregnancy, and postpartum/early parenthood.\n",
    "\n",
    "## Executive Summary\n",
    "### Data Collection\n",
    "Data was collected on August 7, 2020 using the [Pushshift Reddit API](https://github.com/pushshift/api). This API allows for easy aggregation of posts from Reddit.com. For each health domain, data was collected that spanned from August 7, 2020 to February 16, 2019 (a period of approximately 17.5 months).    \n",
    "\n",
    "**1. General Women's Health Data:**  \n",
    "* Posts relating to general women's health concerns were collected from [r/WomensHealth](https://www.reddit.com/r/WomensHealth/), [r/obgyn](https://www.reddit.com/r/obgyn/), and [r/thegirlsurvivalguide](https://www.reddit.com/r/TheGirlSurvivalGuide/). \n",
    "* This resulted in a total of 31,385 posts from 19,753 unique users.\n",
    "\n",
    "**2. Fertility and Pregnancy Data:**  \n",
    "* Posts relating to fertility and pregnancy were collected from [r/TryingForABaby](https://www.reddit.com/r/TryingForABaby/), [r/pregnant](https://www.reddit.com/r/pregnant/), and [r/BabyBumps]https://www.reddit.com/r/BabyBumps/). \n",
    "* This resulted in a total of 98,138 posts from 35,127 unique users.\n",
    "\n",
    "**3. Postpartum and Early Parenthood Data:**\n",
    "* Posts relating to the postpartum period and early parenthood were collected from [r/beyondthebump](https://www.reddit.com/r/beyondthebump/), [r/postpartumdepression](https://www.reddit.com/r/postpartumdepression/), and [r/breastfeeding](https://www.reddit.com/r/breastfeeding/).\n",
    "* This resulted in a total of 51,674 posts from 21,585 unique users.\n",
    "\n",
    "### Data Cleaning and Preprocessing\n",
    "Once data was in hand, all data was cleaned to check for missing values and inappropriate data types. HTML tags, Reddit-specific tags (e.g. \"[removed]\", \"[deleted]\"), URLs, and digits were removed from the text. \n",
    "\n",
    "Once the data was cleaned, a custom list of stop words was defined, and posts were lemmatized using ***spaCy***. (Lemmatization refers to the process of reducing a word to its base root.) \n",
    "\n",
    "Prior to modeling, a document term matrix was created using the tf-idf vectorizer by ***sklearn***. (Tf-idf creates a bag of words with a weight for each word that is based upon the number of times a word appears in a post and the number of posts that it appears in. If a word appears in many documents, it will receive a low ranking.) If a ***gensim*** model was used, the document term matrix was further processed to create a ***gensim*** corpus. \n",
    "\n",
    "### Topic Modeling\n",
    "NOT YET COMPLETED - I will update this once I have finalized the models. I think that I will most likely have KMeans Clustering and LDA. I might also try Hierarchical Clustering and NNMF.\n",
    "\n",
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Gensim\n",
    "from gensim import matutils\n",
    "from gensim import corpora\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LsiModel, LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# NLTK\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# pyLDAvis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "# re\n",
    "import re\n",
    "\n",
    "# Scikit Learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Scipy\n",
    "import scipy.sparse\n",
    "\n",
    "\n",
    "# spaCy\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Silence Future Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read-In Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "health = pd.read_csv('../data/womens_health.csv', index_col = 'Unnamed: 0')\n",
    "obsgyn = pd.read_csv('../data/fertility_and_pregnancy.csv', index_col = 'Unnamed: 0')\n",
    "pospar = pd.read_csv('../data/postpartum.csv', index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Head and Shape of Each Data Set\n",
    "Before cleaning the data, I want to check the head and shape of each data set. This will allow me to see which columns were scraped using the Pushshift API and to assess the size of each data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Women's Health Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Been to the clinic twice and they don’t know w...</td>\n",
       "      <td>So I’ve been having problems with discharge an...</td>\n",
       "      <td>WomensHealth</td>\n",
       "      <td>1596818251</td>\n",
       "      <td>thecrazedbunny</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-08-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Been to the clinic twice and they don’t know w...   \n",
       "\n",
       "                                            selftext     subreddit  \\\n",
       "0  So I’ve been having problems with discharge an...  WomensHealth   \n",
       "\n",
       "   created_utc          author  num_comments  score  is_self   timestamp  \n",
       "0   1596818251  thecrazedbunny             0      1     True  2020-08-07  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31385, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the general women's health data, before cleaning there are 31,385 posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fertility and Pregnancy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adding to the kitchen sink approach: I just bo...</td>\n",
       "      <td>This time I’m going to be using a menstrual cu...</td>\n",
       "      <td>TryingForABaby</td>\n",
       "      <td>1596839749</td>\n",
       "      <td>lastput1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-08-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Adding to the kitchen sink approach: I just bo...   \n",
       "\n",
       "                                            selftext       subreddit  \\\n",
       "0  This time I’m going to be using a menstrual cu...  TryingForABaby   \n",
       "\n",
       "   created_utc    author  num_comments  score  is_self   timestamp  \n",
       "0   1596839749  lastput1             7      1     True  2020-08-07  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obsgyn.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98138, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obsgyn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to cleaning, the fertility and pregnancy data set has 98,138 posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pospartum and Early Parenthood Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Question about bottles</td>\n",
       "      <td>I'm researching baby bottles and am trying to ...</td>\n",
       "      <td>BabyBumps</td>\n",
       "      <td>1596850138</td>\n",
       "      <td>All_Hail_CC</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-08-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title                                           selftext  \\\n",
       "0  Question about bottles  I'm researching baby bottles and am trying to ...   \n",
       "\n",
       "   subreddit  created_utc       author  num_comments  score  is_self  \\\n",
       "0  BabyBumps   1596850138  All_Hail_CC             4      1     True   \n",
       "\n",
       "    timestamp  \n",
       "0  2020-08-07  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pospar.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51674, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pospar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to cleaning, the raw postpartum and early parenthood data set has 51,674 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "### Combine `title` and `selftext` columns into a `total_text` column\n",
    "\n",
    "Before beginning to clean the text data, it is important to clean the columns that are included in the data frame. \n",
    "\n",
    "The format of a Reddit post consists of a post title (`title`), and there is also an opportunity to write a body of text (`selftext`). For this project, I will be interested in analyzing all text in a post, so I will combine all of the text into a `total_text` column.\n",
    "\n",
    "#### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_total_text(df):\n",
    "    df['total_text'] = df['title'] + ' ' + df['selftext']\n",
    "    df.drop(columns = ['title', 'selftext'], inplace = True)\n",
    "    return df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation for All Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_total_text(health)\n",
    "create_total_text(obsgyn)\n",
    "create_total_text(pospar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Unnecessary Columns\n",
    "\n",
    "For this project, I am interested in using topic modeling to identify areas of concern for each domain of women's health. Therefore, the number of comments and score of each post will not be relevant and will be removed. Because the date is included under `timestamp`, the `created_utc` column will also be removed. The `is_self` column is also not needed and will be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_columns(df):\n",
    "    df.drop(columns = ['created_utc', 'num_comments', 'score', 'is_self'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation for All Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_columns(health)\n",
    "clean_columns(obsgyn)\n",
    "clean_columns(pospar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Null/Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_percent_null(df):\n",
    "    '''Returns the percent of values in each column that are null or missing'''\n",
    "    return (df.isna().sum()/len(df)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation for All Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_percent_null(health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_percent_null(obsgyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_percent_null(pospar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Missing Data\n",
    "\n",
    "Above, we saw that each dataframe is missing some data in the `total_text` column. Because we can not analyze posts without text, any rows with missing data will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health.dropna(inplace = True)\n",
    "obsgyn.dropna(inplace = True)\n",
    "pospar.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Women's Health Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fertility and Pregnancy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsgyn.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postpartum Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pospar.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert `Timestamp` column to a datetime object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(df, column):\n",
    "    df[column] = pd.to_datetime(df[column])\n",
    "    return df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation for All Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_datetime(health, 'timestamp')\n",
    "convert_to_datetime(obsgyn, 'timestamp')\n",
    "convert_to_datetime(pospar, 'timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning\n",
    "In order to reduce the dimensionality of our text vectors, it is important that only text that will contribute meaning remains in the vector. To do this, we will remove any text that is not believed to contribut meaning to the post.\n",
    "\n",
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_string(df, column, string):\n",
    "    df[column] = df[column].str.replace(string, '')\n",
    "\n",
    "\n",
    "def replace_string(df, column, string, replacement):\n",
    "    df[column] = df[column].str.replace(string, replacement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [removed]\n",
    "If moderators of the subreddit feel that the post violates one or more of the subreddit's rules, they will remove content of the post and replace it with a \"[removed]\" tag. Because the [removed] tags will not add any valuable information to the post, these will be removed from posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_string(health, 'total_text', '\\[removed\\]')\n",
    "remove_string(obsgyn, 'total_text', '\\[removed\\]')\n",
    "remove_string(pospar, 'total_text', '\\[removed\\]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\n\n",
    "This is a symbol that indicates a new line. Because we are only interested in the text itself, this tag will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_string(health, 'total_text', '\\n')\n",
    "remove_string(obsgyn, 'total_text', '\\n')\n",
    "remove_string(pospar, 'total_text', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &amp ;\n",
    "\n",
    "Sometimes, the '&' symbol is not displayed, and the HTML reference `&amp;` shows up instead. This text will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_string(health, 'total_text', '&amp;')\n",
    "remove_string(obsgyn, 'total_text', '&amp;')\n",
    "remove_string(pospar, 'total_text', '&amp;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &gt ;\n",
    "Some times, the greater than symbol (>) is not properly displayed, and the HTML reference `&gt;` shows up in its place. I will remove this HTML reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_string(health, 'total_text', '&gt;')\n",
    "remove_string(obsgyn, 'total_text', '&gt;')\n",
    "remove_string(pospar, 'total_text', '&gt;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &lt ;\n",
    "Some times, the less than symbol (<) is not properly displayed, and the HTML reference `&lt;` shows up in its place. I will remove this HTML reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_string(health, 'total_text', '&lt;')\n",
    "remove_string(obsgyn, 'total_text', '&lt;')\n",
    "remove_string(pospar, 'total_text', '&lt;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TL;DR\n",
    "\"TL;DR\" is an abbreviation that stand for \"Too long; Didn't read\" and is meant to provide a brief synopsis of the post. Because these letters will not provide any meaningful inormation, they will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_string(health, 'total_text', 'TL;DR')\n",
    "remove_string(obsgyn, 'total_text', 'TL;DR')\n",
    "remove_string(pospar, 'total_text', 'TL;DR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [deleted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_string(health, 'total_text', 'deleted')\n",
    "remove_string(obsgyn, 'total_text', 'deleted')\n",
    "remove_string(pospar, 'total_text', 'deleted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Website URLs\n",
    "\n",
    "Prior to being able to remove the urls, I will need to reset the indices so that they are in numerical order from 0 to len(data frame). This will allow me to use `.loc` to edit the specific strings in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health.reset_index(drop = True, inplace = True)\n",
    "obsgyn.reset_index(drop = True, inplace = True)\n",
    "pospar.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(df, column):\n",
    "    for i in range(0, len(df)):\n",
    "        df.loc[i, column] = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', df.loc[i, column])\n",
    "        \n",
    "# Regex Code by Lee Martin (Stack Overflow post)\n",
    "# https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python/11332580        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_empty_text(df, column):\n",
    "    df = df[df[column] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove URLs from all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_urls(health, 'total_text')\n",
    "remove_urls(obsgyn, 'total_text')\n",
    "remove_urls(pospar, 'total_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check to see if removing URLs resulted in any null 'total_text'; If so, remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_empty_text(health, 'total_text')\n",
    "delete_empty_text(obsgyn, 'total_text')\n",
    "delete_empty_text(pospar, 'total_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Posts by AutoModerator\n",
    "\n",
    "During EDA, I discovered that several of the subreddits used for data collection have an \"AutoModerator\" user that makes several posts. Because this user does not represent a woman who is interested in asking a health-related question, I will remove all posts from this user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_AutoModerator(df, column):\n",
    "    df = df[df[column] != 'AutoModerator']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation for all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health = remove_AutoModerator(health, 'author')\n",
    "obsgyn = remove_AutoModerator(obsgyn, 'author')\n",
    "pospar = remove_AutoModerator(pospar, 'author')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_digits(df, column1):\n",
    "    df[column1] = df[column1].str.replace('[0-9]+', '', regex = True)\n",
    "    \n",
    "# https://stackoverflow.com/questions/47010044/how-to-remove-numeric-characters-present-in-countvectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation for All Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [health, obsgyn, pospar]\n",
    "\n",
    "for df in dfs:\n",
    "    remove_digits(df, 'total_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit \"C-section\" so that it is not split by the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_string(obsgyn, 'total_text', 'c-section', 'csection')\n",
    "replace_string(obsgyn, 'total_text', 'C-section', 'csection')\n",
    "replace_string(pospar, 'total_text', 'c-section', 'csection')\n",
    "replace_string(obsgyn, 'total_text', 'C-section', 'csection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling with Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
