{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "# Spacy\n",
    "import spacy\n",
    "\n",
    "# Scipy\n",
    "import scipy.sparse\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Gensim\n",
    "from gensim import matutils\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel, LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# NLTK\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Pyldavis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color Palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "blush = '#F7D1CD'\n",
    "pink = '#E8C2CA'\n",
    "light_purple = '#D1B3C4'\n",
    "medium_purple = '#B392AC'\n",
    "dark_purple = '#B392AC'\n",
    "warm_grey = '#8E9AAF'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read-In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health: (30616, 8)\n",
      "ObsGyn: (92943, 8)\n",
      "Pospar: (49094, 8)\n"
     ]
    }
   ],
   "source": [
    "health = pd.read_csv('../data/womens_health_preprocessed.csv', lineterminator='\\n')\n",
    "print(f'Health: {health.shape}')\n",
    "obsgyn = pd.read_csv('../data/fertility_and_pregnancy_preprocessed.csv')\n",
    "print(f'ObsGyn: {obsgyn.shape}')\n",
    "pospar = pd.read_csv('../data/postpartum_preprocessed.csv')\n",
    "print(f'Pospar: {pospar.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stop_words(word_list, list_stop_words):\n",
    "    for word in word_list:\n",
    "        list_stop_words.add(word)\n",
    "        \n",
    "def remove_stop_words(word_list, list_stop_words):\n",
    "    for word in word_list:\n",
    "        list_stop_words.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words_spacy = set(nlp.Defaults.stop_words)\n",
    "\n",
    "# nltk\n",
    "stop_words_nltk = set(stopwords.words('english'))\n",
    "\n",
    "# full list of stop words\n",
    "full_stop_words = stop_words_spacy.union(stop_words_nltk)\n",
    "\n",
    "words_to_add = ['like', 'know', 'want', 'feel', 'going', 'think', 'reddit', 'imgur', 'pron', 'officially', 'story', 'month', 'week', 'time', 'day', 'year', 'delete', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'subreddit']\n",
    "\n",
    "add_stop_words(words_to_add, full_stop_words)\n",
    "remove_stop_words(['not'], full_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Document Term Matrix From Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tvec(df, column, stop_words = full_stop_words):\n",
    "    tvec = TfidfVectorizer(max_df = 0.98, min_df = 0.005, ngram_range = (1,2), stop_words = stop_words)\n",
    "    dtm = tvec.fit_transform(df[column])\n",
    "    return tvec, dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Document Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer, dtm are outputed from build_tvec\n",
    "\n",
    "health_vectorizer, health_dtm = build_tvec(health, 'lemma_text')\n",
    "obsgyn_vectorizer, obsgyn_dtm = build_tvec(obsgyn, 'lemma_text')\n",
    "pospar_vectorizer, pospar_dtm = build_tvec(pospar, 'lemma_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Document Term Matrix into a Term Document Matrix that can be recognized by Gensim\n",
    "\n",
    "**Note**: Code for these steps was modified from [A Dash of Data](https://github.com/adashofdata/nlp-in-python-tutorial) by Alice Zhao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tdm(dtm):\n",
    "    tdm = dtm.transpose()\n",
    "    return tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tdm_to_gensim_corpus(tdm):\n",
    "    sparse = scipy.sparse.csr_matrix(tdm) # Create a compressed sparse row matrix\n",
    "    corpus = matutils.Sparse2Corpus(tdm) # Create a corpus from sparse matrix\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dtm_for_gensim(dtm):\n",
    "    tdm = create_tdm(dtm)\n",
    "    corpus = tdm_to_gensim_corpus(tdm)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_corpus = prepare_dtm_for_gensim(health_dtm)\n",
    "obsgyn_corpus = prepare_dtm_for_gensim(obsgyn_dtm)\n",
    "pospar_corpus = prepare_dtm_for_gensim(pospar_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Vocabulary Dictionary from Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab_dictionary(vectorizer):\n",
    "    vocab_dictionary = dict((v,k) for k,v in vectorizer.vocabulary_.items())\n",
    "    return vocab_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_vocabulary = create_vocab_dictionary(health_vectorizer)\n",
    "obsgyn_vocabulary = create_vocab_dictionary(obsgyn_vectorizer)\n",
    "pospar_vocabulary = create_vocab_dictionary(pospar_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling with Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build LDA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gensim_lda(corpus, n_topics, vocabulary, n_passes):\n",
    "    lda = LdaModel(corpus = corpus, num_topics = n_topics, id2word = vocabulary, passes = n_passes, decay = 0.7, offset = 10, random_state = 2020)\n",
    "    return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gensim_coherence_model(model, corpus, dictionary):\n",
    "    coherence = CoherenceModel(model=model, corpus = corpus, dictionary = dictionary, coherence = 'u_mass')\n",
    "    return round(coherence.get_coherence(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_terms(model, n_topics, n_words):\n",
    "    return model.print_topics(num_topics = n_topics, num_words = n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_lda(corpus, vocabulary, n_passes, start, stop, step_size):\n",
    "    \n",
    "    models_dict = {}\n",
    "    coherence_list = []\n",
    "    \n",
    "    for i in range(start, stop, step_size):\n",
    "        print(f'Building LDA model for {i} topics')\n",
    "        lda_model = build_gensim_lda(corpus, i, vocabulary, n_passes)\n",
    "        models_dict[i] = lda_model # Save model to dictionary with # topics as key\n",
    "        print('Calculating coherence score')\n",
    "        coherence = build_gensim_coherence_model(lda_model, corpus, vocabulary)\n",
    "        coherence_list.append(coherence)\n",
    "#         perplexity = lda_model.log_perplexity(corpus)\n",
    "#         perplexity_list.append(perplexity)\n",
    "    \n",
    "    print('Finished!')\n",
    "    \n",
    "    return models_dict, coherence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Written By Selva Prabhakaran\n",
    "# https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "\n",
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    \n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Percent_Dominant_Topic', 'Keywords', 'Original_Text']\n",
    "    \n",
    "    return sent_topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coherence_by_topic(start, stop, step_size, coherence_list, size = (10,6), title = None, x_label = None, y_label = None):\n",
    "    plt.figure(figsize = size)\n",
    "    sns.lineplot(x = range(start, stop, step_size), y = coherence_list, linewidth = 2, color = dark_purple)\n",
    "    plt.xlabel(x_label, fontdict = {'fontsize':12}, labelpad = 8)\n",
    "    plt.ylabel(y_label, fontdict = {'fontsize':12}, labelpad = 8)\n",
    "    plt.title(title, fontdict = {'fontsize':15}, pad = 8)\n",
    "    plt.xticks(size = 11)\n",
    "    plt.yticks(size = 11)\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Women's Health Data\n",
    "##### Grid Search to Find Optimal Number of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building LDA model for 5 topics\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "failed to initialize distributed LDA (Pyro name server not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/Pyro4/core.py\u001b[0m in \u001b[0;36mconnect_and_handshake\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m    514\u001b[0m                                                \u001b[0mnodelay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_NODELAY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m                                                sslContext=sslContext)\n\u001b[0m\u001b[1;32m    516\u001b[0m                 \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocketutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSocketConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/Pyro4/socketutil.py\u001b[0m in \u001b[0;36mcreateSocket\u001b[0;34m(bind, connect, reuseaddr, keepalive, timeout, noinherit, ipv6, nodelay, sslContext)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mCommunicationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/Pyro4/core.py\u001b[0m in \u001b[0;36m_locateNS\u001b[0;34m(host, port, broadcast, hmac_key)\u001b[0m\n\u001b[1;32m   2008\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2009\u001b[0;31m         \u001b[0mproxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pyroBind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2010\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"located NS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/Pyro4/core.py\u001b[0m in \u001b[0;36m_pyroBind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \"\"\"\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pyroCreateConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/Pyro4/core.py\u001b[0m in \u001b[0;36m__pyroCreateConnection\u001b[0;34m(self, replaceUri, connected_socket)\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m                 \u001b[0mconnect_and_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMETADATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/Pyro4/core.py\u001b[0m in \u001b[0;36mconnect_and_handshake\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m    548\u001b[0m                         \u001b[0mce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCommunicationError\u001b[0m: cannot connect to ('localhost', 9090): [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNamingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mgetNS\u001b[0;34m(host, port, broadcast, hmac_key)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1590\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPyro4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocateNS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhmac_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1591\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mPyro4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/Pyro4/core.py\u001b[0m in \u001b[0;36m_locateNS\u001b[0;34m(host, port, broadcast, hmac_key)\u001b[0m\n\u001b[1;32m   2015\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2016\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNamingError\u001b[0m: Failed to locate the nameserver",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetNS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mns_conf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                     \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlda_dispatcher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLDA_DISPATCHER_PREFIX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mgetNS\u001b[0;34m(host, port, broadcast, hmac_key)\u001b[0m\n\u001b[1;32m   1591\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mPyro4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pyro name server not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Pyro name server not found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9c414e645434>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                           \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                           \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                                           step_size = 1)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-c79b4620ebfd>\u001b[0m in \u001b[0;36mgrid_search_lda\u001b[0;34m(corpus, vocabulary, n_passes, start, stop, step_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Building LDA model for {i} topics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mlda_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_gensim_lda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_passes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmodels_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda_model\u001b[0m \u001b[0;31m# Save model to dictionary with # topics as key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calculating coherence score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-bfe01386f3df>\u001b[0m in \u001b[0;36mbuild_gensim_lda\u001b[0;34m(corpus, n_topics, vocabulary, n_passes)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_gensim_lda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_passes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLdaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_passes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2020\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"failed to initialize distributed LDA (%s)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"failed to initialize distributed LDA (%s)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;31m# Initialize the variational distribution q(beta|lambda)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: failed to initialize distributed LDA (Pyro name server not found)"
     ]
    }
   ],
   "source": [
    "health_lda_models, health_lda_coherence = grid_search_lda(corpus = health_corpus, \n",
    "                                                          vocabulary = health_vocabulary, \n",
    "                                                          n_passes = 25, \n",
    "                                                          start = 5, \n",
    "                                                          stop = 20, \n",
    "                                                          step_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Examine How Coherence Changes with the Number of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coherence_by_topic(5, 20, 1, \n",
    "                        health_lda_coherence_, \n",
    "                        size = (10,6), \n",
    "                        title = 'Coherence Score by Number of Women\\'s Health Topics', \n",
    "                        x_label = 'Number of Topics', \n",
    "                        y_label = 'UMass Coherence Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Examine Topic Composition for Each Number of Topics\n",
    "\n",
    "Because each model that was built in the grid search was stored in a model dictionary where the number of topics was the key, we can easily access the model to explore the topics that were created. \n",
    "\n",
    "For example, for the model with 6 topics, the following code can be used to retrieve the top 10 terms for each of the 6 topics.\n",
    "\n",
    "```python\n",
    "health_lda_6 = health_lda_models[6]\n",
    "\n",
    "get_topic_terms(health_lda_6, 6, 10)\n",
    "```\n",
    "This was done for each several numbers of topics. At each step of the way, the topic clusters were evaluated to determine if the clusters made sense and if any loss in cohesion was offset by a gain in knowledge about a woman's health concern. After this process, 15 topics was determined to be the optimal number of topics for the general women's health data. Therefore, a new model was fit with the identified number of topics. To ensure, optimal allocation of topics, the model was allowed to run for 100 iterations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a Final LDA model with topic number chosen from review of grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_lda_model = build_gensim_lda(health_corpus, \n",
    "                               n_topics = 15, \n",
    "                               vocabulary = health_vocabulary, \n",
    "                               n_passes = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(health_lda_model, open('health_lda_model.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topic_terms(health_lda_model, 15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_gensim_coherence_model(health_lda_model, corpus = health_corpus, dictionary = health_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyLDAvis.gensim.prepare(df_lda_17, health_corpus, health_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fertility and Pregnancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsgyn_lda_models, obsgyn_lda_coherence = grid_search_lda(corpus = obsgyn_corpus, \n",
    "                                                          vocabulary = obsgyn_vocabulary, \n",
    "                                                          n_passes = 25, \n",
    "                                                          start = 2, \n",
    "                                                          stop = 30, \n",
    "                                                          step_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coherence_by_topic(2, 30, 2, \n",
    "                        obsgyn_lda_coherence, \n",
    "                        size = (10,6), \n",
    "                        title = 'Coherence Score by Number of Fertility and Pregnancy Topics', \n",
    "                        x_label = 'Number of Topics', \n",
    "                        y_label = 'UMass Coherence Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsgyn_lda_model = build_gensim_lda(obsgyn_corpus, \n",
    "                               n_topics = 12, \n",
    "                               vocabulary = obsgyn_vocabulary, \n",
    "                               n_passes = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topic_terms(obsgyn_lda_model, 12, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_gensim_coherence_model(obsgyn_lda_model, corpus = obsgyn_corpus, dictionary = obsgyn_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(obsgyn_lda_model, open('../pickles/obsgyn_lda_model.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postpartum Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pospar_lda_models, pospar_lda_coherence = grid_search_lda(corpus = pospar_corpus, \n",
    "                                                          vocabulary = pospar_vocabulary, \n",
    "                                                          n_passes = 25, \n",
    "                                                          start = 2, \n",
    "                                                          stop = 30, \n",
    "                                                          step_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coherence_by_topic(2, 30, 2, \n",
    "                        pospar_lda_coherence, \n",
    "                        size = (10,6), \n",
    "                        title = 'Coherence Score by Number of Pospartum/Early Parenthood Topics', \n",
    "                        x_label = 'Number of Topics', \n",
    "                        y_label = 'UMass Coherence Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pospar_lda_model = build_gensim_lda(pospar_corpus, \n",
    "                               n_topics = 22, \n",
    "                               vocabulary = pospar_vocabulary, \n",
    "                               n_passes = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topic_terms(pospar_lda_model, 22, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(pospar_lda_model, open('../pickles/pospar_lda_model.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
